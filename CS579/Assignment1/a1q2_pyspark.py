# -*- coding: utf-8 -*-
"""A1Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n2YeCmi2kcqDMyABFH4yr55SNFBIWnnj
"""

!apt-get install openjdk-8-jdk-headless -qq
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop3.2.tgz
!tar xf spark-3.0.0-preview2-bin-hadoop3.2.tgz
!pip install -q findspark
!ls

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-preview2-bin-hadoop3.2"

import findspark
findspark.init()
from pyspark.sql import SparkSession
from pyspark.ml.regression import LinearRegression
from pyspark.ml.feature import VectorAssembler
spark = SparkSession.builder.master("local[*]").getOrCreate()

def load_Data(file):
  df = spark.read.format("csv").options(header='true').load(file)
  for col in df.columns:
    if col not in ['id', 'date']:
      df = df.withColumn(col, df[col].cast('float'))
  feature_cols = df.columns[3:]

  return df, feature_cols

train_df, feature_cols = load_Data('training.csv')
test_df, _ = load_Data('testing.csv')

vectorAssembler = VectorAssembler(inputCols=feature_cols, outputCol='features')
train_df = vectorAssembler.transform(train_df)
test_df = vectorAssembler.transform(test_df)

lr = LinearRegression(featuresCol='features', labelCol='price')
lrModel = lr.fit(train_df)

predictions = lrModel.transform(test_df)
predictions.toPandas().loc[:, ['id','price','prediction']].to_csv('predictions.csv', index=False)
